{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 and 2\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Task 2 and 4\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import collections\n",
    "\n",
    "# Task 3\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import json\n",
    "import shapely\n",
    "from shapely.geometry import Point, MultiPoint, LineString, MultiLineString, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = {}\n",
    "\n",
    "PATH[\"data_raw\"] = \"../data/raw/\"\n",
    "PATH[\"data_interim\"] = \"../data/interim/\"\n",
    "PATH[\"data_processed\"] = \"../data/processed/\"\n",
    "PATH[\"data_external\"] = \"../data/external/\"\n",
    "\n",
    "FILENAME = {}\n",
    "FILENAME[\"accidents\"] = \"Road Safety Data - Accidents 2019.csv\"\n",
    "FILENAME[\"casualties\"] = \"Road Safety Data - Casualties 2019.csv\"\n",
    "FILENAME[\"vehicles\"] = \"Road Safety Data- Vehicles 2019.csv\" # Note the inconsistent naming of the raw data files\n",
    "\n",
    "TABLENAMES = [\"accidents\", \"casualties\", \"vehicles\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data from the csv files,headerraw takes the label,done it this way to maintain 2d numpy array and not flatten it\n",
    "dataraw_masked = {}\n",
    "headerraw = {}\n",
    "for tablename in TABLENAMES:\n",
    "    headerraw[tablename]= np.genfromtxt(PATH[\"data_raw\"] + FILENAME[tablename], delimiter = ',',encoding='utf-8-sig',dtype=str)[0,:]\n",
    "    dataraw_masked[tablename] = np.genfromtxt(PATH[\"data_raw\"] + FILENAME[tablename], delimiter = ',',encoding='utf-8-sig',dtype=None)[1:,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the first 5 rows of the accidents to see how the data looks\n",
    "dataraw_masked[\"accidents\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the mask for the city of Liverpool, 91 is the code for the city of Liverpool\n",
    "city_mask = [bool(x) for x in dataraw_masked[\"accidents\"][:,np.where(headerraw[\"accidents\"]==\"Local_Authority_(District)\")] == \"91\"] #Liverpool district\n",
    "#creating the dataset of rows coresponding to the city of Liverpool for the accident circumstances\n",
    "liverpoolRaw = dataraw_masked[\"accidents\"][city_mask]\n",
    "#Getting the accident index from the Liverpool dataset\n",
    "ind = [x[0] for x in liverpoolRaw]\n",
    "\n",
    "#Getting the data specific to Liverpool from the casualties and vehicles file\n",
    "#by matching the accident index form the accidents file with the one from the other two \n",
    "data_casualties = dataraw_masked[\"casualties\"][np.isin(dataraw_masked[\"casualties\"][:,0], ind)]\n",
    "data_vehicles = dataraw_masked[\"vehicles\"][np.isin(dataraw_masked[\"vehicles\"][:,0], ind)]\n",
    "\n",
    "#The same accident index might appear multiple entries since they are reffering to different persons who were part of the accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting the liverpool dataset to an excel file\n",
    "#No other cleaning has been done to this dataset ,because the missing values were given rid of by slicing the 2d numpy array when the figures are created\n",
    "df_data_accidents_live = pd.DataFrame(liverpoolRaw,columns=headerraw[\"accidents\"])\n",
    "df_data_vehicles_liv = pd.DataFrame(data_vehicles,columns=headerraw[\"vehicles\"])\n",
    "df_data_casualty_liv=pd.DataFrame(data_casualties,columns=headerraw[\"casualties\"])\n",
    "filepath = PATH[\"data_processed\"] + 'liverpool_dataset.xlsx'\n",
    "writer = pd.ExcelWriter(filepath, engine = 'xlsxwriter')\n",
    "\n",
    "df_data_accidents_live.to_excel(writer,sheet_name='accidents_liverpool', index=False)\n",
    "df_data_vehicles_liv.to_excel(writer,sheet_name='vehicles_liverpool', index=False)\n",
    "df_data_casualty_liv.to_excel(writer,sheet_name='casualties_liverpool', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the dataset using df.info() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_accidents_live.info()\n",
    "print()\n",
    "df_data_vehicles_liv.info()\n",
    "print()\n",
    "df_data_casualty_liv.info()\n",
    "#At first it can be seen that dataset is pretty clean and that each attributes does not seem to miss values\n",
    "#all variables are of type object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a mask that doens't take into consideration the missing data, in this case the missing date correspond to \"-1\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [bool(x) for x in data_vehicles[:,np.where(headerraw[\"vehicles\"]==\"Age_Band_of_Driver\")] > \"-1\"]\n",
    "data_vehicles_clear = data_vehicles[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_age_of_casualties = {2: \"6-10\", 3: \"11-15\", 4: \"16-20\", 5: \"21-25\", 6: \"26-35\", 7: \"36-45\", 8: \"46-55\", 9: \"56-65\", 10: \"66-75\", 11: \"Over 75\"}\n",
    "\n",
    "#Getting the categories and counts for the age band of driver\n",
    "categories_age, counts_age = np.unique(data_vehicles_clear[:,np.where(headerraw[\"vehicles\"]==\"Age_Band_of_Driver\")], return_counts=True)\n",
    "\n",
    "#need to do this because np.unique does not preserve the inital order\n",
    "categories_age=np.concatenate((categories_age[2:],categories_age[:2]))\n",
    "counts_age= np.concatenate((counts_age[2:],counts_age[:2]))\n",
    "\n",
    "####################################################################################################\n",
    "day_of_the_week = {1: \"Sunday\",2: \"Monday\", 3: \"Tuesday\", 4: \"Wednesday\", 5: \"Thursday\", 6: \"Friday\", 7: \"Saturday\" }\n",
    "\n",
    "#Getting the categories and counts for accidents in liverpool during different days of the week\n",
    "categories_week_day, counts_week_day = np.unique(liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Day_of_Week\")], return_counts=True)\n",
    "#############################################################################################\n",
    "#the dates of the year are a numpy arayy of numpy arrays, with the multiple comprehension list it has been unpack,probably not the best way\n",
    "dates_of_year =liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Date\")]\n",
    "flat_list = [item for sublist in dates_of_year for item in sublist]\n",
    "flat_list2 =[item for sublist in flat_list for item in sublist]\n",
    "\n",
    "#Getting the month out of the date variable from the accident circumstances datasets\n",
    "months = [x[3:5] for x in flat_list2]\n",
    "\n",
    "categories_month, counts_month = np.unique(months, return_counts=True)\n",
    "####################################################################################################\n",
    "\n",
    "road_surface_categories = {1: \"Dry\", 2: \"Wet or damp\", 3: \"Snow\", 4: \"Frost or ice\", 5: \"Flood over 3cm. deep\"}\n",
    "\n",
    "#Creating a mask so that the missing data are not taking into consideration\n",
    "road_cond_clean_mask= [bool(x) for x in liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Road_Surface_Conditions\")]!=\"-1\"]\n",
    "road_cond_clean = liverpoolRaw[road_cond_clean_mask]\n",
    "\n",
    "#Getting the categories and counts for accidents in liverpool for different road surface conditions\n",
    "categories_road_cond, counts_road_cond = np.unique(road_cond_clean[:,np.where(headerraw[\"accidents\"]==\"Road_Surface_Conditions\")], return_counts=True)\n",
    "\n",
    "#Creating the figure which has 4 subplots\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(50, 45))\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 26}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.subplots_adjust( hspace=0.2)\n",
    "\n",
    "# Draw first subplot using plt.subplot\n",
    "plt.subplot(2, 2, 1)\n",
    "av1= plt.bar(categories_age, counts_age, fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "\n",
    "plt.xticks([str(x) for x in band_age_of_casualties.keys()],band_age_of_casualties.values(),rotation=45)\n",
    "plt.title(\"Accidents by different age groups in Liverpool\")\n",
    "plt.ylabel('Number of people')\n",
    "plt.xlabel('Band Age')\n",
    "\n",
    "# Draw first subplot using plt.subplot\n",
    "plt.subplot(2, 2, 2)\n",
    "av1= plt.bar(categories_week_day, counts_week_day, fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "\n",
    "plt.xticks([str(x) for x in day_of_the_week.keys()],day_of_the_week.values(),rotation=45)\n",
    "plt.title(\"Accidents in different days of the week in Liverpool,in one year\")\n",
    "plt.ylabel('Number of people per day')\n",
    "plt.xlabel('Day of the week')\n",
    "\n",
    "# Draw first subplot using plt.subplot\n",
    "plt.subplot(2, 2, 3)\n",
    "av1= plt.bar(categories_month, counts_month, fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "\n",
    "plt.title(\"Accidents for different months in Liverpool\")\n",
    "plt.ylabel('Number of people per month')\n",
    "plt.xlabel('Month of the year')\n",
    "\n",
    "# Draw first subplot using plt.subplot\n",
    "plt.subplot(2, 2, 4)\n",
    "av1= plt.bar(categories_road_cond, counts_road_cond, fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "\n",
    "plt.xticks([str(x) for x in road_surface_categories.keys()],road_surface_categories.values(),rotation=45)\n",
    "plt.title(\"Accidents in different road surface conditions in Liverpool\")\n",
    "plt.ylabel('Accident count')\n",
    "plt.xlabel('Road Surface Condition')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to find association between Road Type and 1st Point of Impact,the code from here can be used for the second task\n",
    "\n",
    "liverpoolRaw1 = liverpoolRaw\n",
    "\n",
    "#Created a Counter which has data about how many time a accident_index is repeated in the vehicle dataset\n",
    "accident_index_count= collections.Counter(data_vehicles[:,0])\n",
    "\n",
    "#In this for, to the accident circumstances from liverpool dataset it is added some iddentical rows so that the shape of dataset is the same as the vehicle dataset\n",
    "for i,x in enumerate(liverpoolRaw[:,0]):\n",
    "    if(accident_index_count[x]!=1):\n",
    "        liverpoolRaw1=np.append(liverpoolRaw1,np.tile(liverpoolRaw[i],(accident_index_count[x]-1,1)),axis=0)\n",
    "\n",
    "#The array must be sorted by the index so that it matches the indexes from the vehicle dataset\n",
    "sorted_live= liverpoolRaw1[liverpoolRaw1[:,0].argsort()]\n",
    "###################################################################################################################\n",
    "\n",
    "age_band_day_week = np.array([[int(x) for x in data_vehicles[:,np.where(headerraw[\"vehicles\"]==\"Age_Band_of_Driver\")]],\n",
    "                                [int(x) for x in sorted_live[:,np.where(headerraw[\"accidents\"]==\"Day_of_Week\")]]]).T\n",
    "\n",
    "observed_pd = pd.crosstab(age_band_day_week[:, 0], age_band_day_week[:, 1], rownames = [\"Age_Band_of_Driver\"], colnames = [\"Day_of_Week\"]) \n",
    "observed_as1 = observed_pd.to_numpy()\n",
    "print(observed_pd)\n",
    "rowTotals = observed_as1.sum(axis = 1) # R\n",
    "N = rowTotals.sum()\n",
    "chiVal_as1, pVal_as1, df_as1, expected_as1 = chi2_contingency(observed_as1)\n",
    "chiVal_as1, pVal_as1, df_as1, expected_as1.astype(int)\n",
    "print(\"The p value is:\",pVal_as1)\n",
    "V_as1 = np.sqrt( (chiVal_as1/N) / (min(observed_as1.shape)-1) )\n",
    "print(\"The cramer V for the age band of driver and day of week :\",V_as1)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=7, figsize=(35, 20))\n",
    "\n",
    "weekday_labels = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "age_categories = {2: \"6-10\", 3: \"11-15\", 4: \"16-20\", 5: \"21-25\", 6: \"26-35\", 7: \"36-45\", 8: \"46-55\", 9: \"56-65\", 10: \"66-75\", 11: \"75 and up\"}\n",
    "\n",
    "x = np.array(list(age_categories.keys()))\n",
    "# print(observed[1:].shape)\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.plot(x, observed_as1[1:,i], 'ro-', label='Observed')\n",
    "    ax.plot(x, expected_as1[1:,i], 'bo-', label='Expected')\n",
    "    if i==0: \n",
    "        ax.set_ylabel('Accidents')\n",
    "        ax.legend(loc='best');\n",
    "    ax.set_title(weekday_labels[i])\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(list(age_categories.values()))\n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    ax.plot(x, observed_as1[1:,i]/expected_as1[1:,i], 'go-')\n",
    "    ax.plot(x, np.ones(x.shape), 'k:')\n",
    "    \n",
    "    if i==0: \n",
    "        ax.set_ylabel('Observed/Expected')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(list(age_categories.values()))\n",
    "    fig.autofmt_xdate(rotation=80)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform the array of tuples into a normal np.array.\n",
    "acc_raw = []\n",
    "for row in liverpoolRaw:\n",
    "    r = [i for i in row]\n",
    "    acc_raw.append(r)\n",
    "acc_raw = np.array(acc_raw)\n",
    "print(\"Length of the raw data for Liverpool:\",len(acc_raw))\n",
    "\n",
    "# We check if there are any empty cells in ouy array and print the row number.\n",
    "print(\"\\nThese rows have empty cells:\")\n",
    "for idx, row in enumerate(acc_raw):\n",
    "    for i in row:\n",
    "        if bool(i) == False:\n",
    "            print(idx)\n",
    "\n",
    "print(\"\\nWe'll check what is missing in the rows:\")            \n",
    "print(acc_raw[591], \"\\n\", acc_raw[730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that row 591 has an empty timestamp, this doenst matter for the visualization. \n",
    "# Row 730 has missing latitude and longtitude. \n",
    "# We make the array again, but skip row 730.\n",
    "acc_cleaned = []\n",
    "for idx, row in enumerate(liverpoolRaw):\n",
    "    r = []\n",
    "    for i in row:\n",
    "        r.append(i)\n",
    "    if idx != 730:\n",
    "        acc_cleaned.append(r)\n",
    "acc_cleaned = np.array(acc_cleaned)\n",
    "print(\"Length of array after cleaning:\",len(acc_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create the two types of maps. \n",
    "\n",
    "latlons = np.vstack((acc_cleaned[:,4], acc_cleaned[:,3])).T\n",
    "latlons = latlons.astype(np.float)\n",
    "\n",
    "centroid = list(MultiPoint(latlons).centroid.coords)[0]\n",
    "\n",
    "m1 = folium.Map(centroid, zoom_start=11)\n",
    "\n",
    "for row in acc_cleaned:\n",
    "    # The colors are changed according the severity of the accident.\n",
    "    if int(row[6]) == 1:   col = \"#000935\"; # Fatal --> Black markers\n",
    "    elif int(row[6]) == 2: col = \"#4265ff\"; # Serious --> Blue markers\n",
    "    elif int(row[6]) == 3: col = \"#90a4ff\"; # Slight --> Light blue markers\n",
    "    folium.CircleMarker([row[4], row[3]],\n",
    "                        radius = 5,\n",
    "                        popup = row[0] + \"\\n\" + row[9] + \", \" + row[11], #acc index, date, time\n",
    "                        color = col,\n",
    "                        legend_name=\"Severaty\"\n",
    "                       ).add_to(m1)\n",
    "    \n",
    "HeatMap(latlons).add_to(folium.FeatureGroup(name='Heat Map').add_to(m1))\n",
    "folium.LayerControl().add_to(m1)\n",
    "m1.save(\"../reports/figures/map1.html\")\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 2 with marker clusters, almost the same code as map 1. \n",
    "\n",
    "latlons = np.vstack((acc_cleaned[:,4], acc_cleaned[:,3])).T\n",
    "latlons = latlons.astype(np.float)\n",
    "\n",
    "centroid = list(MultiPoint(latlons).centroid.coords)[0]\n",
    "\n",
    "m2 = folium.Map(centroid, zoom_start=11)\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(folium.FeatureGroup(name='Clusters').add_to(m2))\n",
    "\n",
    "for row in acc_cleaned:\n",
    "    # The colors are changed according the severity of the accident.\n",
    "    if int(row[6]) == 1:   col = \"#000935\"; # Fatal --> Black markers\n",
    "    elif int(row[6]) == 2: col = \"#4265ff\"; # Serious --> Blue markers\n",
    "    elif int(row[6]) == 3: col = \"#90a4ff\"; # Slight --> Light blue markers\n",
    "    folium.CircleMarker([row[4], row[3]],\n",
    "                        radius = 5,\n",
    "                        popup = row[0] + \"\\n\" + row[9] + \", \" + row[11], #acc index, date, time\n",
    "                        color = col,\n",
    "                       ).add_to(marker_cluster)\n",
    "    \n",
    "HeatMap(latlons).add_to(folium.FeatureGroup(name='Heat Map').add_to(m2))\n",
    "folium.LayerControl().add_to(m2)\n",
    "m2.save(\"../reports/figures/map2.html\")\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create mask for fatalities on the liverpool dataset and create a numpy array with the rows which have an acident which is fatal\n",
    "# accident severity 1:Fatal and 2:Serious\n",
    "acc_sev_mask1a= [bool(x) for x in liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]==\"1\"] \n",
    "acc1a= liverpoolRaw[acc_sev_mask1a]\n",
    "acc_sev_mask2a= [bool(x) for x in liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]==\"2\"]\n",
    "acc2a= liverpoolRaw[acc_sev_mask2a]\n",
    "\n",
    "road_types_cat = {1:\"Roundabout\",2:\"One way street\",3:\"Dual carriageway\",6:\"Single carriageway\" }\n",
    "\n",
    "categories1a, counts1a = np.unique(acc1a[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")], return_counts=True)\n",
    "categories2a, counts2a = np.unique(acc2a[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")], return_counts=True)\n",
    "#resize the numpy array of fatalities counts so that it matches the size of counts of \n",
    "countx = np.pad(counts1a, ( counts2a.size-counts1a.size,0), 'constant')\n",
    "\n",
    "#################################################################################################\n",
    "#for all the data from the dataset\n",
    "#Creating masks so that we get just the serious and fatal accidents\n",
    "acc_sev_mask1b= [bool(x) for x in dataraw_masked[\"accidents\"][:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]==\"1\"]\n",
    "acc1b= dataraw_masked[\"accidents\"][acc_sev_mask1b]\n",
    "acc_sev_mask2b= [bool(x) for x in dataraw_masked[\"accidents\"][:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]==\"2\"]\n",
    "acc2b= dataraw_masked[\"accidents\"][acc_sev_mask2b]\n",
    "\n",
    "road_types_cat2 = {1:\"Roundabout\",2:\"One way street\",3:\"Dual carriageway\",6:\"Single carriageway\",7:\"Slip road\"}\n",
    "\n",
    "categories1b, counts1b = np.unique(acc1b[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")], return_counts=True)\n",
    "categories2b, counts2b = np.unique(acc2b[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")], return_counts=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to found out if there is any association between Accident Severity and Road Type for Liverpool\n",
    "\n",
    "liv_clean_data_mask1 = [bool(x) for x in liverpoolRaw[:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]<\"3\"]\n",
    "liv_clean_data= liverpoolRaw[liv_clean_data_mask1]\n",
    "road_type_acc_sev = np.array([[int(x) for x in liv_clean_data[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")]],\n",
    "                          [int(x) for x in liv_clean_data[:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]]]).T\n",
    "\n",
    "\n",
    "observed_pd_liv = pd.crosstab(road_type_acc_sev[:, 0], road_type_acc_sev[:, 1], rownames = [\"Road_Type\"], colnames = [\"Accident Severity\"]) \n",
    "observed_liv = observed_pd_liv.to_numpy()\n",
    "\n",
    "rowTotals = observed_liv.sum(axis = 1) # R\n",
    "N = rowTotals.sum()\n",
    "chiVal, pVal, df, expected_liv = chi2_contingency(observed_liv)\n",
    "chiVal, pVal, df, expected_liv.astype(int)\n",
    "print(\"The p value for Liverpool is:\",pVal)\n",
    "V = np.sqrt( (chiVal/N) / (min(observed_liv.shape)-1) )\n",
    "print(\"The cramer V for the road type and accidents severity for Liverpool:\",V)\n",
    "########################################################################################################\n",
    "#Try to found out if there is any association between Accident Severity and Road Type for UK\n",
    "#Trying to compare the p values and Cramer V values between Liverpool and the all UK\n",
    "uk_clean_data_mask1 = [bool(x) for x in dataraw_masked[\"accidents\"][:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]<\"3\"]\n",
    "uk_clean_data= dataraw_masked[\"accidents\"][uk_clean_data_mask1]\n",
    "road_type_acc_sev_uk = np.array([[int(x) for x in uk_clean_data[:,np.where(headerraw[\"accidents\"]==\"Road_Type\")]],\n",
    "                          [int(x) for x in uk_clean_data[:,np.where(headerraw[\"accidents\"]==\"Accident_Severity\")]]]).T\n",
    "\n",
    "\n",
    "observed_pd_uk = pd.crosstab(road_type_acc_sev_uk[:, 0], road_type_acc_sev_uk[:, 1], rownames = [\"Road_Type\"], colnames = [\"Accident Severity\"]) \n",
    "observed_uk = observed_pd_uk.to_numpy()\n",
    "observed_uk=observed_uk[:-2]\n",
    "rowTotals = observed_uk.sum(axis = 1) # R\n",
    "N = rowTotals.sum()\n",
    "chiVal, pVal, df, expected_uk = chi2_contingency(observed_uk)\n",
    "chiVal, pVal, df, expected_uk.astype(int)\n",
    "print(\"The p value for all UK is:\",pVal)\n",
    "V = np.sqrt( (chiVal/N) / (min(observed_uk.shape)-1) )\n",
    "print(\"The cramer V for the road type and accidents severity for all UK:\",V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the figure with 6 different subplots\n",
    "fig = plt.figure(num=None, figsize=(50, 45))\n",
    "font = {'family' : 'Times New Roman',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 24}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.subplots_adjust( hspace=0.3)\n",
    "\n",
    "# Draw first subplot using plt.subplot\n",
    "plt.subplot(3, 2, 1)\n",
    "av1= plt.bar(categories2a, counts2a, fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "av2 =plt.bar(categories2a, countx,bottom=counts2a, fc=\"r\",alpha=0.6,edgecolor='black')\n",
    "\n",
    "plt.xticks([str(x) for x in road_types_cat.keys()],road_types_cat.values(),rotation=45)\n",
    "plt.ylabel('Accident counts')\n",
    "plt.title(\"Accident counts per road type in Liverpool\")\n",
    "plt.legend((av1[0], av2[0]), ('Serious', 'Fatal'))\n",
    "\n",
    "# Draw second subplot using plt.subplot\n",
    "#Slicing the counts and categories since unknown and slid road are not significant\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.bar(categories1b[:-2],counts1b[:-2],bottom=counts2b[:-2], fc=\"r\",alpha=0.6,edgecolor='black')\n",
    "plt.bar(categories2b[:-2],counts2b[:-2], fc=\"b\",alpha=0.6,edgecolor='black')\n",
    "plt.xticks([str(x) for x in road_types_cat.keys()],road_types_cat.values(),rotation=45)\n",
    "\n",
    "plt.legend((av1[0], av2[0]), ('Serious', 'Fatal'))\n",
    "plt.title(\"Accident counts per road type in UK\")\n",
    "\n",
    "\n",
    "#For Liverpool\n",
    "road_type_catx = np.array(list(road_types_cat.keys()))\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(road_type_catx, observed_liv[:,0], 'ro-', label='Observed')\n",
    "plt.plot(road_type_catx, expected_liv[:,0], 'bo-', label='Expected')\n",
    "\n",
    "plt.xticks(road_type_catx,road_types_cat.values(),rotation=45)\n",
    "plt.legend((av1[0], av2[0]), ('Expected', 'Observed'))\n",
    "plt.title(\"Fatal injuries for multiple road types,Observed vs Expected,Liverpool\")\n",
    "plt.ylabel('Accident counts')\n",
    "\n",
    "\n",
    "#Draw 2\n",
    "road_type_catx = np.array(list(road_types_cat.keys()))\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot(road_type_catx, observed_liv[:,1], 'ro-', label='Observed')\n",
    "plt.plot(road_type_catx, expected_liv[:,1], 'bo-', label='Expected')\n",
    "\n",
    "plt.xticks(road_type_catx,road_types_cat.values(),rotation=45)\n",
    "plt.legend((av1[0], av2[0]), ('Expected', 'Observed'))\n",
    "plt.title(\"Serious injuries for multiple road types,Observed vs Expected,Liverpool\")\n",
    "plt.ylabel('Accident counts')\n",
    "\n",
    "\n",
    "\n",
    "#For Uk\n",
    "road_type_catx = np.array(list(road_types_cat.keys()))\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.plot(road_type_catx, observed_uk[:,0], 'ro-', label='Observed')\n",
    "plt.plot(road_type_catx, expected_uk[:,0], 'bo-', label='Expected')\n",
    "# plt.plot(road_type_catx, observed_uk[:,0]/expected_uk[:,0], 'go-')\n",
    "# plt.plot(road_type_catx, np.ones(road_type_catx.shape), 'k:')\n",
    "plt.xticks(road_type_catx,road_types_cat.values(),rotation=45)\n",
    "plt.legend((av1[0], av2[0]), ('Expected', 'Observed'))\n",
    "plt.xlabel('Road type')\n",
    "plt.title(\"Fatal injuries for multiple road types,Observed vs Expected,UK\")\n",
    "plt.ylabel('Accident counts')\n",
    "\n",
    "road_type_catx = np.array(list(road_types_cat.keys()))\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.plot(road_type_catx, observed_uk[:,1], 'ro-', label='Observed')\n",
    "plt.plot(road_type_catx, expected_uk[:,1], 'bo-', label='Expected')\n",
    "# plt.plot(road_type_catx, observed_uk[:,1]/expected_uk[:,1], 'go-')\n",
    "# plt.plot(road_type_catx, np.ones(road_type_catx.shape), 'k:')\n",
    "plt.xticks(road_type_catx,road_types_cat.values(),rotation=45)\n",
    "plt.legend((av1[0], av2[0]), ('Expected', 'Observed'))\n",
    "plt.xlabel('Road type')\n",
    "plt.title(\"Fatal injuries for multiple road types,Observed vs Expected,UK\")\n",
    "plt.ylabel('Accident counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
